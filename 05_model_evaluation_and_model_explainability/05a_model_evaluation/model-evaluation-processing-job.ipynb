{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation using SageMaker Processing Job\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "3. [Setup](#Setup)\n",
    "4. [Dataset](#Dataset)\n",
    "5. [Build a SageMaker Processing Job](#Build-a-SageMaker-Processing-Job)\n",
    "    1. [Prepare the Script and Docker File](#Prepare-the-Script-and-Docker-File)\n",
    "    2. [Configure a ScriptProcessor](#Configure-a-ScriptProcessor)\n",
    "6. [Review Outputs](#Review-Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Postprocess and Model evaluation is an important step to vet out models before deployment. In this lab you will use ScriptProcessor from SageMaker Process to build a post processing step after model training to evaluate the performance of the model.  \n",
    "\n",
    "To setup your ScriptProcessor, we will build a custom container for a model evaluation script which will Load the tensorflow model, Load the test dataset and annotation (either from previous module or run the `optional-prepare-data-and-model.ipynb` notebook), and then run predicition and generate the confussion matrix. \n",
    "\n",
    "** Note: This Notebook was tested on Data Science Kernel in SageMaker Studio**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Download the notebook into your environment, and you can run it by simply execute each cell in order. To understand what's happening, you'll need:\n",
    "\n",
    "- Access to the SageMaker default S3 bucket.\n",
    "- Familiarity with Python and numpy\n",
    "- Basic familiarity with AWS S3.\n",
    "- Basic understanding of AWS Sagemaker.\n",
    "- Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "- SageMaker Studio is preferred for the full UI integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "account = sess.account_id()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket() # or use your own custom bucket name\n",
    "prefix = 'postprocessing-modal-evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset we are using is from [Caltech Birds (CUB 200 2011)](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html). **If you kept your artifacts from previous labs, then simply update the s3 location below for you Test images and Test data annotation file.  If you do not have them, just run the `optional-prepare-data-and-model.ipynb` notebook to generate the files, and then update the path below.**\n",
    "\n",
    "- S3 path for test image data\n",
    "- S3 path for test data annotation file\n",
    "- S3 path for the bird classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_images = f's3://{bucket}/{prefix}/outputs/test/'\n",
    "s3_manifest = f's3://{bucket}/{prefix}/outputs/manifest'\n",
    "s3_model = f's3://{bucket}/{prefix}/postprocessing-modal-evaluation-2022-03-25-23-23-23-103/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Script and Docker File\n",
    "With SageMaker, you can run data processing jobs using the SKLearnProcessor, popular ML frameworks processors, Apache Spark, or BYOC.  To learn more about [SageMaker Processing](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html)\n",
    "\n",
    "For this example we are going to practice using ScriptProcess and Bring Our Own Container (BYOC). ScriptProcess require you to feed a container uri from ECR and a custom script for the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the script below does:\n",
    "1. loading the tf model\n",
    "2. looping through the annotation file to run inference predictions\n",
    "3. tally the results using sklearn libraries & generate the confusion matrix\n",
    "4. save the metrics in a evaluation.json report as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile evaluation.py\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import uuid\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# from smexperiments import tracker\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "input_path =  \"/opt/ml/processing/input/test\" #\"output/test\" #\n",
    "manifest_path = \"/opt/ml/processing/input/manifest/test.csv\"#\"output/manifest/test.csv\"\n",
    "model_path = \"/opt/ml/processing/model\" #\"model\" # \n",
    "output_path = '/opt/ml/processing/output' #\"output\" # \n",
    "\n",
    "HEIGHT=224; WIDTH=224\n",
    "\n",
    "def predict_bird_from_file_new(fn, model):\n",
    "    \n",
    "    img = Image.open(fn).convert('RGB')\n",
    "    \n",
    "    img = img.resize((WIDTH, HEIGHT))\n",
    "    img_array = image.img_to_array(img) #, data_format = \"channels_first\")\n",
    "\n",
    "    x = img_array.reshape((1,) + img_array.shape)\n",
    "    instance = preprocess_input(x)\n",
    "\n",
    "    del x, img\n",
    "    \n",
    "    result = model.predict(instance)\n",
    "\n",
    "    predicted_class_idx = np.argmax(result)\n",
    "    confidence = result[0][predicted_class_idx]\n",
    "\n",
    "    return predicted_class_idx, confidence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-file\", type=str, default=\"model.tar.gz\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    logger.debug(\"Extracting the model\")\n",
    "\n",
    "    model_file = os.path.join(model_path, args.model_file)\n",
    "    file = tarfile.open(model_file)\n",
    "    file.extractall(model_path)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    logger.debug(\"Load model\")\n",
    "\n",
    "    model = keras.models.load_model(\"{}/1\".format(model_path))\n",
    "\n",
    "    logger.debug(\"Starting evaluation.\")\n",
    "    \n",
    "    # load test data.  this should be an argument\n",
    "    df = pd.read_csv(manifest_path)\n",
    "    \n",
    "    num_images = df.shape[0]\n",
    "    \n",
    "    class_name_list = sorted(df['class_id'].unique().tolist())\n",
    "    \n",
    "    class_name = pd.Series(df['class_name'].values,index=df['class_id']).to_dict()\n",
    "    \n",
    "    logger.debug('Testing {} images'.format(df.shape[0]))\n",
    "    num_errors = 0\n",
    "    preds = []\n",
    "    acts  = []\n",
    "    for i in range(df.shape[0]):\n",
    "        fname = df.iloc[i]['image_file_name']\n",
    "        act   = int(df.iloc[i]['class_id']) - 1\n",
    "        acts.append(act)\n",
    "        \n",
    "        pred, conf = predict_bird_from_file_new(input_path + '/' + fname, model)\n",
    "        preds.append(pred)\n",
    "        if (pred != act):\n",
    "            num_errors += 1\n",
    "            logger.debug('ERROR on image index {} -- Pred: {} {:.2f}, Actual: {}'.format(i, \n",
    "                                                                   class_name_list[pred], conf, \n",
    "                                                                   class_name_list[act]))\n",
    "    precision = precision_score(acts, preds, average='micro')\n",
    "    recall = recall_score(acts, preds, average='micro')\n",
    "    accuracy = accuracy_score(acts, preds)\n",
    "    cnf_matrix = confusion_matrix(acts, preds, labels=range(len(class_name_list)))\n",
    "    f1 = f1_score(acts, preds, average='micro')\n",
    "    \n",
    "    logger.debug(\"Accuracy: {}\".format(accuracy))\n",
    "    logger.debug(\"Precision: {}\".format(precision))\n",
    "    logger.debug(\"Recall: {}\".format(recall))\n",
    "    logger.debug(\"Confusion matrix: {}\".format(cnf_matrix))\n",
    "    logger.debug(\"F1 score: {}\".format(f1))\n",
    "    \n",
    "    logger.debug(cnf_matrix)\n",
    "    \n",
    "    matrix_output = dict()\n",
    "    \n",
    "    for i in range(len(cnf_matrix)):\n",
    "        matrix_row = dict()\n",
    "        for j in range(len(cnf_matrix[0])):\n",
    "            matrix_row[class_name[class_name_list[j]]] = int(cnf_matrix[i][j])\n",
    "        matrix_output[class_name[class_name_list[i]]] = matrix_row\n",
    "\n",
    "    \n",
    "    report_dict = {\n",
    "        \"multiclass_classification_metrics\": {\n",
    "            \"accuracy\": {\"value\": accuracy, \"standard_deviation\": \"NaN\"},\n",
    "            \"precision\": {\"value\": precision, \"standard_deviation\": \"NaN\"},\n",
    "            \"recall\": {\"value\": recall, \"standard_deviation\": \"NaN\"},\n",
    "            \"f1\": {\"value\": f1, \"standard_deviation\": \"NaN\"},\n",
    "            \"confusion_matrix\":matrix_output\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a custom docker container and push to ECR\n",
    "\n",
    "You can use the standard TFflow container, but ScriptProcessor currently does not support `source_dir` for custom requirement.txt and multiple python file.  That is on the roadmap, please follow this [thread](https://github.com/aws/sagemaker-python-sdk/issues/1248) for updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/requirements.txt\n",
    "# This is the set of Python packages that will get pip installed\n",
    "# at startup of the Amazon SageMaker endpoint or batch transformation. \n",
    "Pillow\n",
    "scikit-learn\n",
    "pandas\n",
    "numpy\n",
    "tensorflow==2.1\n",
    "boto3==1.18.4\n",
    "sagemaker-experiments\n",
    "matplotlib==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM public.ecr.aws/docker/library/python:3.7\n",
    "    \n",
    "ADD requirements.txt /\n",
    "\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE \n",
    "ENV TF_CPP_MIN_LOG_LEVEL=\"2\"\n",
    "\n",
    "ENTRYPOINT [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to build a container image and push to ECR is to use studion image builder. This require certain permission for your sagemaker execution role, please follow this [blog](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/) to update your role policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name = \"sagemaker-tf-container\"\n",
    "!cd docker && sm-docker build . --file Dockerfile --repository $container_name:2.0\n",
    "    \n",
    "ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}:2.0\".format(account, region, container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a ScriptProcessor\n",
    "1) copy the ecr uri from the step above\n",
    "2) initialize the Process (instance count, instance type, etc.)\n",
    "3) run the processing job (define script path, input arguments, input and output file locations\n",
    "\n",
    "Note: we are not using GPU, so you can ignore the CUDA warning message. You can add the corresponding libraries to you docker file if you want use GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput, Processor\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import uuid\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "image_uri = ecr_image\n",
    "\n",
    "s3_evaluation_output = f's3://{bucket}/{prefix}/outputs/evaluation'\n",
    "\n",
    "\n",
    "script_processor = ScriptProcessor(base_job_name = prefix,\n",
    "                command=['python3'],\n",
    "                image_uri=image_uri,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_processor.run(\n",
    "                        code='evaluation.py',\n",
    "                        arguments=[\"--model-file\", \"model.tar.gz\"],\n",
    "                        inputs=[ProcessingInput(source=s3_images, \n",
    "                                                destination=\"/opt/ml/processing/input/test\"),\n",
    "                                ProcessingInput(source=s3_manifest, \n",
    "                                                destination=\"/opt/ml/processing/input/manifest\"),\n",
    "                                ProcessingInput(source=s3_model, \n",
    "                                                destination=\"/opt/ml/processing/model\"),\n",
    "                               ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", \n",
    "                                             destination=s3_evaluation_output),\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs\n",
    "\n",
    "At the end of the lab, you will generate a json file containing the performance metrics (accuracy, precision, recall, f1, and confusion matrix) on your test dataset.  Run the cell below to review the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "s3 = boto3.resource('s3')\n",
    "eval_matrix_key = f'{prefix}/outputs/evaluation/evaluation.json'\n",
    "content_object = s3.Object(bucket, eval_matrix_key)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "\n",
    "pp.pprint(json_content['multiclass_classification_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
