{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Dataset](#Dataset)\n",
    "3. [Preprocessing the Dataset](#Preprocessing)\n",
    "4. [Setup Parameters for Model Training](#Setup-Parameters-for-Model-Training)\n",
    "5. [Model Training](#Model-Training)\n",
    "6. [Deploy SageMaker Model](#Deploy-SageMaker-model)\n",
    "7. [Setup Clarify Job Parameters](#Set-up-Clarify-config)\n",
    "8. [Run Clarify Explainability](#Run-Clarify-Explainability)\n",
    "9. [Evaluate Outputs](#Evaluate-Output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### This notebook  will prepare the dataset and model for the model explainability lab.  This is an optional step if you have kept your artifacts from previous modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and initialize parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "account = sess.account_id()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket() # or use your own custom bucket name\n",
    "prefix = 'clarify-explainability'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset we are using is from [Caltech Birds (CUB 200 2011)](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) dataset contains 11,788 images across 200 bird species (the original technical report can be found here). Each species comes with around 60 images, with a typical size of about 350 pixels by 500 pixels. Bounding boxes are provided, as are annotations of bird parts. A recommended train/test split is given, but image size data is not.\n",
    "\n",
    "### Run the cell below to download the full dataset or download manually [here](https://course.fast.ai/datasets). Note that the file size is around 1.2 GB, and can take a while to download.If you plan to complete the entire workshop, please keep the file to avoid re-download and re-process the data.\n",
    "\n",
    "### Downloading the dataset and Uploading the images to S3 takes approx 10-15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget 'https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz'\n",
    "!tar xopf CUB_200_2011.tgz\n",
    "!rm CUB_200_2011.tgz\n",
    "\n",
    "s3_raw_data = f's3://{bucket}/{prefix}/full/data'\n",
    "!aws s3 cp --recursive ./CUB_200_2011 $s3_raw_data\n",
    "!rm -rf ./CUB_200_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timpstamp = str(time.time()).split('.')[0]\n",
    "# SKlearnProcessor for preprocessing\n",
    "output_prefix = f'{prefix}/outputs'\n",
    "output_s3_uri = f's3://{bucket}/{output_prefix}'\n",
    "\n",
    "class_selection = '13, 17, 35, 36, 47, 68, 73, 87'\n",
    "input_annotation = 'classes.txt'\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(base_job_name = f\"{prefix}-preprocess\",  # choose any name\n",
    "                                    framework_version='0.20.0',\n",
    "                                    role=role,\n",
    "                                    instance_type=processing_instance_type,\n",
    "                                    instance_count=processing_instance_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step takes 7-10 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor.run(\n",
    "    code='preprocessing.py',\n",
    "    arguments=[\"--classes\", class_selection, \n",
    "               \"--input-data\", input_annotation],\n",
    "    inputs=[ProcessingInput(source=s3_raw_data, \n",
    "            destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output/train\", destination = output_s3_uri +'/train'),\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output/valid\", destination = output_s3_uri +'/valid'),\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output/test\", destination = output_s3_uri +'/test'),\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output/manifest\", destination = output_s3_uri +'/manifest'),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where your images and annotation files are located.  You will need these for this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test dataset located here: {output_s3_uri +'/test'} ===========\")\n",
    "\n",
    "print(f\"Test annotation file is located here: {output_s3_uri +'/manifest'} ===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Parameters for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "TF_FRAMEWORK_VERSION = '2.1'\n",
    "\n",
    "hyperparameters = {'initial_epochs':     5,\n",
    "                   'batch_size':         8,\n",
    "                   'fine_tuning_epochs': 20, \n",
    "                   'dropout':            0.4,\n",
    "                   'data_dir':           '/opt/ml/input/data'}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',      'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "                  {'Name': 'acc',       'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "                  {'Name': 'val_loss',  'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "                  {'Name': 'val_acc',   'Regex': 'val_accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "\n",
    "distribution = {'parameter_server': {'enabled': False}}\n",
    "DISTRIBUTION_MODE = 'FullyReplicated'\n",
    "    \n",
    "train_in = TrainingInput(s3_data=output_s3_uri +'/train', distribution=DISTRIBUTION_MODE)\n",
    "val_in   = TrainingInput(s3_data=output_s3_uri +'/valid', distribution=DISTRIBUTION_MODE)\n",
    "test_in  = TrainingInput(s3_data=output_s3_uri +'/test', distribution=DISTRIBUTION_MODE)\n",
    "\n",
    "inputs = {'train':train_in, 'test': test_in, 'validation': val_in}\n",
    "\n",
    "training_instance_type = 'ml.c5.4xlarge'\n",
    "\n",
    "training_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"s3://{bucket}/{prefix}\"\n",
    "\n",
    "estimator = TensorFlow(entry_point='train-mobilenet.py',\n",
    "               source_dir='code',\n",
    "               output_path=model_path,\n",
    "               instance_type=training_instance_type,\n",
    "               instance_count=training_instance_count,\n",
    "               distribution=distribution,\n",
    "               hyperparameters=hyperparameters,\n",
    "               metric_definitions=metric_definitions,\n",
    "               role=role,\n",
    "               framework_version=TF_FRAMEWORK_VERSION, \n",
    "               py_version='py3',\n",
    "               base_job_name=prefix,\n",
    "               script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "### Train the model - This step takes 12-15 minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model_name = f\"{prefix}-classification-model-{timestamp_suffix}\"\n",
    "\n",
    "\n",
    "serializer = IdentitySerializer(content_type=\"image/jpeg\")\n",
    "deserializer = JSONDeserializer(accept='application/json')\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "model_artifacts = f'{model_path}/{training_job_name}/output/model.tar.gz'\n",
    "\n",
    "model = TensorFlowModel(name=model_name,\n",
    "              model_data=model_artifacts,\n",
    "              source_dir='code',\n",
    "              entry_point='inference.py',\n",
    "              role=sagemaker.get_execution_role(),\n",
    "              framework_version=TF_FRAMEWORK_VERSION,\n",
    "              sagemaker_session=sess)\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m5.xlarge',\n",
    "                         serializer=serializer,\n",
    "                         deserializer = deserializer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a single image to validate model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "BUCKET_NAME = f'{bucket}'\n",
    "BUCKET_FILE_NAME = 'clarify-explainability/outputs/test/017.Cardinal/Cardinal_0001_17057.jpg'\n",
    "LOCAL_FILE_NAME = 'Cardinal_0001_17057.jpg'\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(BUCKET_NAME, BUCKET_FILE_NAME, LOCAL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till you see the downloaded image in your local directory\n",
    "### The output class prediction of model should be 017.Cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "possible_classes = ['013.Bobolink',\n",
    "                    '017.Cardinal',\n",
    "                    '035.Purple_Finch',\n",
    "                    '036.Northern_Flicker',\n",
    "                    '047.American_Goldfinch',\n",
    "                    '068.Ruby_throated_Hummingbird',\n",
    "                    '073.Blue_Jay',\n",
    "                    '087.Mallard']\n",
    "\n",
    "fn = 'Cardinal_0001_17057.jpg'\n",
    "\n",
    "with open(fn, 'rb') as img:\n",
    "    f = img.read()\n",
    "    x = bytearray(f)\n",
    "    results = predictor.predict(x)\n",
    "    predicted_class_idx = argmax(results)\n",
    "    predicted_class = possible_classes[predicted_class_idx]\n",
    "\n",
    "predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "objects = s3_client.list_objects_v2(Bucket=bucket, Prefix=f'{output_prefix}/test/')\n",
    "\n",
    "for obj in objects['Contents']:\n",
    "    rnd_num = random.randint(1, 10)\n",
    "    \n",
    "    if rnd_num == 1:\n",
    "        filename =obj['Key'].split('/')[-1]\n",
    "        copy_source = {\n",
    "            'Bucket': bucket,\n",
    "            'Key': obj['Key']\n",
    "        }\n",
    "        print (filename)\n",
    "        print (obj['Key'])\n",
    "        print (bucket)\n",
    "        s3_client.copy(copy_source, bucket, f'{prefix}/clarify-images/{filename}')\n",
    "        s3_client.download_file(bucket, obj['Key'], f'{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_categories = class_selection.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Clarify config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: We are using only a subset of images for Clarify to speed up processing. If you would like to use the entire dataset please update the s3_data_input_path to the following in the next cell\n",
    "### s3_data_input_path = f's3://{bucket}/{prefix}/clarify-images'\n",
    "\n",
    "### Setting up Clarify Job parameters for Image Classification in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "s3_data_input_path = f's3://{bucket}/{output_prefix}/test/017.Cardinal'\n",
    "clarify_output_prefix = f\"{prefix}/cv_analysis_result\"\n",
    "analysis_result_path = \"s3://{}/{}\".format(bucket, clarify_output_prefix)\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=s3_data_input_path,\n",
    "    s3_output_path=analysis_result_path,\n",
    "    dataset_type=\"application/x-image\",\n",
    ")\n",
    "\n",
    "image_config = clarify.ImageConfig(\n",
    "    model_type=\"IMAGE_CLASSIFICATION\", num_segments=20, segment_compactness=5\n",
    ")\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name, instance_type=\"ml.m5.xlarge\", instance_count=1,content_type=\"image/jpeg\"\n",
    ")\n",
    "\n",
    "shap_config = clarify.SHAPConfig(num_samples=500, image_config=image_config)\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(label_headers=object_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "account_id = os.getenv(\"AWS_ACCOUNT_ID\", \"<your-account-id>\")\n",
    "sagemaker_iam_role = \"<AmazonSageMaker-ExecutionRole>\"\n",
    "\n",
    "# Fetch the IAM role to initialize the sagemaker processing job\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    role = f\"arn:aws:iam::{account_id}:role/{sagemaker_iam_role}\"\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, instance_count=1, instance_type=\"ml.m5.xlarge\", sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Clarify Explainability\n",
    "### The entire set of images in the Cardinal folder takes appox. 45-50 minutes to complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    "    model_scores=predictions_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output_objects = s3_client.list_objects(Bucket=bucket, Prefix=clarify_output_prefix)\n",
    "result_images = []\n",
    "\n",
    "for file_obj in output_objects[\"Contents\"]:\n",
    "    file_name = os.path.basename(file_obj[\"Key\"])\n",
    "    if os.path.splitext(file_name)[1] == \".jpeg\":\n",
    "        result_images.append(file_name)\n",
    "\n",
    "    print(f\"Downloading s3://{bucket}/{file_obj['Key']} ...\")\n",
    "    s3_client.download_file(bucket, file_obj[\"Key\"], file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Output\n",
    "### View the SHAP values and Pixel Heat Maps for the Images in this notebook\n",
    "### You can also download the report.pdf from your local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "for img in result_images:\n",
    "    display(Image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
