{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Tuning\n",
    "\n",
    "In this notebook we will train the model on the data we prepared in [Module 1: Preprocessing](../01_preprocessing/data_preprocessing.ipynb) using the AWS-managed Tensorflow container and a script describing the model used for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and initialize parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "boto3_session = boto3.Session()\n",
    "sagemaker_client = boto3_session.client(\"sagemaker\")\n",
    "\n",
    "account = sagemaker_session.account_id()\n",
    "region = sagemaker_session.boto_region_name\n",
    "default_bucket = sagemaker_session.default_bucket() # or use your own custom bucket name\n",
    "prefix = 'cv-sagemaker-immersionday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_prefix = f'{prefix}/outputs' #prefix generated by data processing module\n",
    "processed_data_s3_uri = f's3://{default_bucket}/{processed_data_prefix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Model Tuning\n",
    "\n",
    "[Amazon SageMaker automatic model tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html), also known as hyperparameter optimization (HPO), finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure HPO Job\n",
    "Next, the tuning job with the following configurations need to be specified:\n",
    "- hyperparameters that SageMaker Automatic Model Tuning will tune: `dropout`, `batch-size`;\n",
    "- maximum number of training jobs it will run to optimize the objective metric: `6`\n",
    "- number of parallel training jobs that will run in the tuning job: `2`\n",
    "- the objective metric that Automatic Model Tuning will use is the accuracy of the validation data: `val_acc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'loss',      'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'acc',       'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'val_loss',  'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'val_acc',   'Regex': 'val_accuracy: ([0-9\\\\.]+)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "TF_FRAMEWORK_VERSION = '2.4.1'\n",
    "DISTRIBUTION = {'parameter_server': {'enabled': False}}\n",
    "DISTRIBUTION_MODE = 'FullyReplicated'\n",
    "    \n",
    "training_instance_type = 'ml.c5.4xlarge'\n",
    "training_instance_count = 1\n",
    "shared_hyperparameters = { \"initial_epochs\": 5, 'fine_tuning_epochs': 20, 'data_dir': '/opt/ml/input/data' }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"train-mobilenet.py\",\n",
    "    source_dir=\"code\",\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=training_instance_count,   \n",
    "    hyperparameters=shared_hyperparameters,    \n",
    "    metric_definitions=metric_definitions,     \n",
    "    role=role,\n",
    "    framework_version=TF_FRAMEWORK_VERSION, \n",
    "    py_version='py37',     \n",
    "    base_job_name=prefix,\n",
    "    script_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"dropout\": ContinuousParameter(0.5, 0.8),\n",
    "    \"batch-size\": CategoricalParameter([8 , 16, 32, 64, 128, 256])\n",
    "}\n",
    "\n",
    "objective_metric_name = \"val_acc\"\n",
    "\n",
    "train_in = TrainingInput(s3_data=processed_data_s3_uri +'/train', distribution=DISTRIBUTION_MODE)\n",
    "val_in   = TrainingInput(s3_data=processed_data_s3_uri +'/valid', distribution=DISTRIBUTION_MODE)\n",
    "test_in  = TrainingInput(s3_data=processed_data_s3_uri +'/test', distribution=DISTRIBUTION_MODE)\n",
    "\n",
    "inputs = {'train':train_in, 'test': test_in, 'validation': val_in}\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    objective_type=\"Maximize\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    base_tuning_job_name=\"cv-hpo\",\n",
    ")\n",
    "\n",
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the experiment associated to the HPO job\n",
    "\n",
    "[SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) helps you organize, track, compare and evaluate machine learning (ML) experiments and model versions. SInce ML is a highly iterative process, Experiment helps data scientists and ML engineers to explore thousands of different models in an organized manner.  Exspecially when you are using tools like [Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) and [Amazon SageMaker Autopilot](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html), it will help you explore a large number of combinations automatically, and quickly zoom in on high-performance models.\n",
    "\n",
    "The tuning job has an experiment automatically associated with it and we can explore the results in the SageMaker user interface. \n",
    "\n",
    "![hpo-experiment](statics/hpo-experiment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access the best model programatically as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_uri = tuner.best_estimator().latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print(f\"\\nBest model artifact file is uploaded here: {training_job_uri}\")\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
